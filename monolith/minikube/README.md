

## Kubernetes

### Что такое Kubernetes?

**Kubernetes** является проектом с открытым исходным кодом, предназначенным для управления кластером контейнеров Linux как единой системой. Kubernetes управляет и запускает контейнеры Docker на большом количестве хостов, а так же обеспечивает совместное размещение и репликацию большого количества контейнеров. Проект был начат Google и теперь поддерживается многими компаниями, среди которых Microsoft, RedHat, IBM и Docker.


### Концепции Kubernetes

- **Nodes**: Нода это машина в кластере Kubernetes.
- **Pods**: Pod это группа контейнеров с общими разделами, запускаемых как единое целое.
- **Replication Controllers**: replication controller гарантирует, что определенное количество «реплик» pod'ы будут запущены в любой момент времени.
- **Services**: Сервис в Kubernetes это абстракция которая определяет логический объединённый набор pod и политику доступа к ним.
- **Volumes**: Volume(раздел) это директория, возможно, с данными в ней, которая доступна в контейнере.
- **Labels**: Label'ы это пары ключ/значение которые прикрепляются к объектам, например pod'ам. Label'ы могут быть использованы для создания и выбора наборов объектов.
  Kubectl Command Line Interface (kubectl.md): kubectl интерфейс командной строки для управления Kubernetes.

## Minikube

**Minikube** — это упрощенная реализация полноценного Kubernetes-кластера.
Minikube позволяет быстро развернуть простой кластер Kubernetes на своей локальной машине. Такой кластер хорошо подойдет для первого знакомства с Kubernetes или для локальной разработки приложений. Minikube позволяет легко включать или выключать возможности «большого» Kubernetes (вроде Ingress-контроллера или дашборда) с помощью аддонов.

## Установка Minikube и необходимых компонентов
[Официальная инструкция](https://kubernetes.io/ru/docs/tasks/tools/install-minikube/) 
### Краткая инструкция:
<details><summary> kubectl </summary>

`curl -LO https://dl.k8s.io/release/`curl -LS https://dl.k8s.io/release/stable.txt`/bin/linux/amd64/kubectl` 

`chmod +x ./kubectl`

`sudo mv ./kubectl /usr/local/bin/kubectl`

#### Проверка установки: 
`kubectl version --client`
</details>

<details><summary> VirtualBox</summary>

[Ссылка](https://www.virtualbox.org/wiki/Linux_Downloads) на пакеты для linux \
[Ссылка](https://download.virtualbox.org/virtualbox/7.0.10/VirtualBox-7.0.10-158379-OSX.dmg) для MacOS

</details>

<details><summary> Minikube</summary>

#### установка: 
`curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64`

`chmod +x minikube`

`sudo mkdir -p /usr/local/bin/`

`sudo install minikube /usr/local/bin/`
#### запуск: 
`minikube start`\
`minikube status`
</details>

## Описание Minikube в проекте

Все необходимое для запуска одноузлового кластера с проектом находится в папке minikube. Скрипт `main.sh` запускает minikube, а затем последовательно запускает скрипты `create.sh` в каждой из папок `api`, `cache`, `db`.
В `create.sh` выполняются следующие команды:

`envsubst < ./tpl/${service}_deployment.tpl > ${service}_deployment.yaml`  
`envsubst < ./tpl/${service}_service.tpl > ${service}_service.yaml`

Эти команды заменяют переменные окружения в файле с разрешением .tpl и создает/пересоздает файл с разрешением .yaml.
Для каждого из трех сервисов в проекте создается два объекта - **deployment** и **service**.
>**ReplicaSet** — контроллер, позволяющий создать набор одинаковых подов и работать с ними, как с единой сущностью. Поддерживает нужное количество реплик, при необходимости создавая новые поды или убивая старые.

>**Deployment** — контроллер развертывания, являющийся абстракцией более высокого уровня над ReplicaSet'ом. Добавляет возможность обновления управляемых подов.

>**Service** — отвечает за сетевое взаимодействие группы подов. В системе обычно существует несколько экземляров одного микросервиса, соответственно каждый из них имеет свой IP-адрес. Количество подов может изменяться, следовательно набор адресов также не постоянен. Другим частям системы для доступа к рассматриваемым подам нужен какой-то статичный адрес, который Service и предоставляет.

- `kubectl apply -f ${service}_deployment.yaml`
- `kubectl apply -f ${service}_service.yaml`

Эти команды применяют конфигурацию к ресурсу по имени файла или стандартному вводу. Ресурс будет создан, если он еще не существует. Принимаются форматы JSON и YAML.

## Запуск
>`main.sh` - файл запускающий minikube и все скрипты `create.sh` для создания манифестов.

Для обновления манифестов конкретного сервиса, ввиду изменения переменных env-файла, необходимо запустить `create.sh` в папке соответствующего сервиса.

>Для изменения структуры манифестов необходимо изменять файлы *.tpl* в соответствующей папке.

## Minikube Dashboard

**Kubernetes Dashboard** — простой в работе инструмент для получения актуальных сведений о работающем кластере и минимального управления им. Откройте новый терминал и запустите:  
`minikube dashboard`  
Команда `dashboard` активирует дополнение dashboard и открывает прокси в веб-браузере по умолчанию. В этой панели можно создавать такие Kubernetes-ресурсы, как **Deployment** и **Service**.  
По умолчанию панель доступна только из внутренней виртуальной сети Kubernetes. Команда `dashboard` создаёт временный прокси, чтобы панель была доступна извне внутренней виртуальной сети Kubernetes.  
Чтобы остановить работу прокси, выполните `Ctrl+C` для завершения процесса. Когда команда завершит работу, панель останется запущенной внутри кластера Kubernetes. Вы можете снова выполнить команду `dashboard`, чтобы создать новую прокси для доступа к панели.

## Тестирование

Убедимся, что приложение работает, с помощью команды:

`kubectl get pods`

В списке должны присутствовать три деплоймента, созданные скриптом main.sh.
Чтобы узнать, на каком хосте доступно наше приложение, нужно ввести команду:

`minikube ip`

Чтобы узнать название сервиса в кластере, нужно ввести команду:

`kubectl get services`

Чтобы узнать, какой порт был открыт для внешнего мира, выполним подкоманду `describe service` c названием сервиса:

`kubectl describe services/tradeapi-service`

В поле `NodePort` указан необходимый нам порт.

Далее по адресу `host:port/swagger` можно переходить к тестированию API.






